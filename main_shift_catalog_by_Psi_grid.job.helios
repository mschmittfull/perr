#!/bin/bash -l

# # required time of job
#SBATCH -t 12:00:00
# # number of processors (helios has 28 cores per node; 896 is half cluster)
# # For Nptcles=NgridOut=512, need few minutes on 28 cores
# # For Nptcles=1536, need few minutes on 448 cores
# # or half an hour on -n 224 cores
# # For Nptcles=2500, get OOM error for 448 cores, need SBATCH -n 896, srun -n 448
#SBATCH -n 448
#SBATCH --mem=120GB
#SBATCH --export=ALL
#SBATCH -V
#SBATCH --mail-user=mschmittfull@gmail.com
#SBATCH --mail-type=ALL
#SBATCH --output=slurm-%x.o%j
#SBATCH --error=slurm-%x.e%j
#SBATCH -J shift
#SBATCH --exclusive
# #SBATCH --dependency=afterok:7655459

set -x

module load helios
module load openmpi/1.10.7_gcc-4.8.5
module load gsl/gcc-4.8.5/2.4

export MPICH_GNI_MBOXES_PER_BLOCK=4096
# was 2
export OMP_NUM_THREADS=2
# (can use half of allocated processors below so we can use 2 threads)

# 1536 for ms_gadget, 2500 for IllustrisTNG
Nptcles=1536
NmeshInternal=1536  # should be >=Nptcles
NgridOut=512
# 1: Zeldovich, 2: 2LPT
PsiOrder=1
# 0: No RSD, 1: Include RSD
RSD=0


conda activate nbodykit-0.3.7-env

myscript=main_ms_gadget_shift_catalog_by_Psi_grid.py_$(date +%s%N)
cp main_shift_catalog_by_Psi_grid.py $myscript

#for SimSeed in 0
#for SimSeed in 400
for SimSeed in 400 401 402 403 404
do
    # use 2 threads so here should be half of cores requested by SBATCH -n above
    srun -n 224 python $myscript $Nptcles $NgridOut --Nmesh=$NmeshInternal --SimSeed=$SimSeed --PsiOrder=$PsiOrder --RSD=$RSD
done
        
conda deactivate                

